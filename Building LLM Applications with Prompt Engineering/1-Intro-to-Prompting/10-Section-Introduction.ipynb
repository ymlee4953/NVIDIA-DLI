{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744d0a4f-6751-4683-91ed-b6639447a018",
   "metadata": {},
   "source": [
    "![NVIDIA](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ebc37-2bdc-4094-9bad-671bd6d4faa5",
   "metadata": {},
   "source": [
    "# Section 1: Introduction to Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fadf7-f01e-439d-b592-9980dd44364d",
   "metadata": {},
   "source": [
    "This section is the beginning of grand endeavor into working programmatically with large language models by way of prompt engineering. In this section you'll start with the most basic of considerations, like what kinds of models are we going to work with today, and how can we send prompts to them and view their responses. You'll gradually build towards more complex prompts, and begin learning about the vast surface area of helpful tooling for working with large language models provided to us by LangChain. But you may be surprised, even with the introductory techniques covered in this section, by the end you'll be performing exercises that demonstrate the capacity to perform a significant amount of working using large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf92848-0eda-4fdf-8226-c48c017969f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10016277-0c6a-4de3-b7ca-aec1a8949228",
   "metadata": {},
   "source": [
    "## Section Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f938cd-c20c-4c6a-a09b-33b2437661fd",
   "metadata": {},
   "source": [
    "1. **NVIDIA NIM for Prompt Engineering:** In this notebook we introduce NVIDIA NIMs and how we are going to be using them in today's course environment.\n",
    "2. **Hello World with the OpenAI Library:** In this notebook, you will learn how to interact with the OpenAI API to generate text completions using the Llama 3.1 8b model.\n",
    "3. **Hello World with LangChain:** In this notebook, we will learn how to interact with LangChain to generate chat completions using the Llama 3.1 8b model.\n",
    "4. **Streaming and Batching:** In this notebook you'll learn how to stream model responses and handle multiple chat completion requests in batches.\n",
    "5. **Iterative Prompt Development:** In this notebook, you will learn the importance of iterating on prompts to achieve the desired responses from an LLM and explore how to write prompts that are specific.\n",
    "6. **Prompt Templates:** In this notebook you'll learn how to capture reusable LLM functionality in prompt templates, and begin working with the powerful prompt template tools provided by LangChain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
