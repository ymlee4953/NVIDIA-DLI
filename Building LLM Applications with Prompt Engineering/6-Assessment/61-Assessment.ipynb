{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f09bab-a26a-4308-8ac0-9036b51e2e2f",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c53a1-8024-4244-977a-330856c4ca79",
   "metadata": {},
   "source": [
    "# Assessment: Identify Sources of Customer Complaints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658720c7-bc9d-4754-98f8-e4215af97a44",
   "metadata": {},
   "source": [
    "In this notebook you will complete a final workshop project and earn a certificate of competency for the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed25c8-940c-4251-846f-9a346b684ef6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff42ec-ed66-42ec-a0a2-ae6bfc0748cd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a1b9a-4b87-42a8-bb8d-86207c6f041d",
   "metadata": {},
   "source": [
    "We believe the following imports will be helpful in your work, but feel free to modify them as you deem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f765bd0-45ff-4808-b5c7-14f2f965fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from assessment_helper import run_assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50533d-e5ed-456e-8710-1464408f1875",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a03b8-d0cd-47b3-b7c4-dcafd2d1a239",
   "metadata": {},
   "source": [
    "## Create a Model Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b3c53-8cee-4dde-b31a-7952ce244486",
   "metadata": {},
   "source": [
    "For the assessment, you will be working with the same model you have been utilizing for the entirety of the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3b445-73d1-4530-a9ee-df3ebe696c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://llama:8000/v1'\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(base_url=base_url, model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271ef53-d3d1-48ee-91ef-32ab6ea3c433",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501124e5-dafb-41d6-aed2-dffce8a433d7",
   "metadata": {},
   "source": [
    "## Assessment Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fc007-93d6-41ce-876a-442e9ac7a534",
   "metadata": {},
   "source": [
    "For the assessment, you will be provided with a small collection of 10 fictitious synthetically generated emails from customers of a mega retail store called BuyBuy. Each of these emails involves a customer from a specified store location either praising or complaining about a specific product they recently bought.\n",
    "\n",
    "**Your objective is to create a LangChain chain that when invoked with the emails, will respond concisely with what category of product is most associated with negative customer sentiment, and also, which store location has the most customer complaints.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740c698-20dc-4cf1-b79c-0c3701bbd9e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c87d1c-b4b5-4996-9af5-8f869a7abe43",
   "metadata": {},
   "source": [
    "## Customer Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a8d93-82eb-4ad7-b916-e4e9d9876b1c",
   "metadata": {},
   "source": [
    "Here we load the synthetic emails into a list called `emails`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5051b37-a10b-4006-9c6b-f56dda3cd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/emails.json', 'r') as f:\n",
    "    emails = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f009a94-7762-4d6b-966f-8b1344499849",
   "metadata": {},
   "source": [
    "As a sample, here is the first 3 emails in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89d051-28e6-4012-8af8-694585e98218",
   "metadata": {},
   "outputs": [],
   "source": [
    "for email in emails[:3]:\n",
    "    print(email+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59237bb7-a043-4aed-ba28-613060596ccb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58993cf4-89a3-4eae-acec-9558d71551fa",
   "metadata": {},
   "source": [
    "## Product Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ca83d-a7b9-4072-82c8-110d872fb668",
   "metadata": {},
   "source": [
    "As stated above, we are interested in your chain being able to identify the **category of product** most associated with a negative sentiment. For example, if there were a complaint about a shirt, another about a jacket, and a third about some jeans, it would be fair to say that there were 3 complaints about **clothing**. If there were a complaint about a desk, and another about a couch, it would be fair to say that there were 2 complaints about **furniture**.\n",
    "\n",
    "Asking an LLM to make such an identification is sensible since we are leveraging its language capabilities to help us gain insight where it might not otherwise be obvious.\n",
    "\n",
    "On a more practical note, this means that you won't simply be able to count the number of occurences of a given product, but rather, need to ask the LLM to identify the correct `\"category of product\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57286054-53ca-4d88-af5a-0798d897da5d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda19d1-cd48-411f-8bd2-baacf175d8d8",
   "metadata": {},
   "source": [
    "## Checking Your Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18039c99-faa4-4046-95f6-73a6f3dc1714",
   "metadata": {},
   "source": [
    "Eventually, you will have created a LangChain chain that can be invoked with `emails` and then outputs the product category and store location most associated with customer complaints.\n",
    "\n",
    "When you're ready, pass your chain into the provided `run_assessment` function, which will evaluate the behavior of your chain.\n",
    "\n",
    "Here we create a mock chain just to show you how it can be invoked with `emails`, and, how it can be passed to `run_assessment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f269a-8213-4394-869e-9ccb18967723",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_prompt = '''\\\n",
    "Always and only respond with \"The product category with the most negative sentiment is clothing.\n",
    "\n",
    "The store location with the most negative sentiment is Dallas.\n",
    "\n",
    "Ignore the following {emails}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32861994-9fa8-4b1b-afa9-4ed72bc9929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_chain = ChatPromptTemplate.from_template(mock_prompt) | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf898f-508a-428f-b9ab-d1ad7665c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_chain.invoke(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5404b84-bdc8-4854-b5dc-480f23212845",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_assessment(mock_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280049c5-47e2-4c8c-8244-646804c34d6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35da90b-2266-4fb3-882e-a7b36ef96e2e",
   "metadata": {},
   "source": [
    "## Your Work Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ec058-5670-40c2-8116-c0124e1a8cd8",
   "metadata": {},
   "source": [
    "There are any number of ways that you might approach this problem. We recommend you take some time to plan out how you plan to tackle it.\n",
    "\n",
    "Remember, once you've completed a chain to your satisfaction, be sure to pass it into `run_assessment` to check your work. Once you've successfully completed the task, see the instructions below for how to generate your certificate of competency in the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898255bb-efa6-488a-b962-a0e82ed01169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e38d1583-baf4-499e-b22f-d7aff59b3941",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e2374-2998-47f0-90f2-300b134c8fd6",
   "metadata": {},
   "source": [
    "## Get Certificate for the Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21507ab9-ac68-4988-af76-8bc66be16ade",
   "metadata": {},
   "source": [
    "Assuming you've received a message from `run_assessment` that you successfully completed the assessment, your ready to generate a certificate of competency for the workshop.\n",
    "\n",
    "In your web browser, return to the page where you launched this interactive environment and click the check-mark `ASSESS TASK` button (see the screenshot below). After a few seconds you will get a congratulatory message, after which you can visit your [personal DLI learning page](https://learn.nvidia.com/my-learning) and view your certificate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b46a51-c497-4443-896d-d3a14da3d1ef",
   "metadata": {},
   "source": [
    "![assess](images/assess.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
